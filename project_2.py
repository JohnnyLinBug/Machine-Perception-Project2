# -*- coding: utf-8 -*-
"""Project_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NJSqeE18dGG3OH8Pm4cIUSJ2l5Df91x6

# Machine Perception Project 2

Members: Johnny Lin, Matt(Zitong) Wei, Boshen Pan

# Create directory

We will store the raw images/raw videos in this directory. If using colab, you will need to upload your videos/images after creating this directory.
"""

import os
custom_dir = "/content/data/nerfstudio/custom_data/raw_images"

if not(os.path.exists(custom_dir)):
  os.makedirs(custom_dir)

custom_vid = "/content/data/nerfstudio/custom_data/raw_video"

if not(os.path.exists(custom_vid)):
  os.makedirs(custom_vid)

"""# Install Nerfstudio and dependencies

"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/
!pip install --upgrade pip
!pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio --extra-index-url https://download.pytorch.org/whl/cu118

# Installing TinyCuda
# %cd /content/
!gdown "https://drive.google.com/u/1/uc?id=1-7x7qQfB7bIw2zV4Lr6-yhvMpjXC84Q5&confirm=t"
!pip install tinycudann-1.7-cp310-cp310-linux_x86_64.whl

!pip install -q condacolab
import condacolab
condacolab.install()
!conda install -c conda-forge colmap

# Install nerfstudio
# %cd /content/
!pip install git+https://github.com/nerfstudio-project/nerfstudio.git

"""Verify whether colmap is installed"""

!colmap -h

"""# Process the images/video

This cell runs COLMAP on your uploaded images/videos.

The output is a set of downsampled images, on which the NerF model runs. You are encouraged to see how the output images look.

"""

scene = 'custom'
!ns-process-data images --data /content/data/nerfstudio/custom_data/raw_images --output-dir /content/data/nerfstudio/custom_data/ --sfm-tool colmap


#!ns-process-data video --data /content/data/nerfstudio/custom_data/raw_video/{vid}.mp4 --output-dir /content/data/nerfstudio/custom_data/ --sfm-tool colmap

# scene = 'poster'
# %cd /content/
# !ns-download-data nerfstudio --capture-name=$scene

"""# Initialize the interactive viewer

We will use an interactive viewer to visualize novel views generated by the NeRF model.
"""

# Commented out IPython magic to ensure Python compatibility.
import os
# %cd /content

# Install localtunnel
# We are using localtunnel https://github.com/localtunnel/localtunnel but ngrok could also be used
!npm install -g localtunnel

# Tunnel port 7007, the default for
!rm url.txt 2> /dev/null
get_ipython().system_raw('lt --port 7007 >> url.txt 2>&1 &')

import time
time.sleep(3) # the previous command needs time to write to url.txt

with open('url.txt') as f:
  lines = f.readlines()
  websocket_url = lines[0].split(": ")[1].strip().replace("https", "wss")
# from nerfstudio.utils.io import load_from_json
# from pathlib import Path
# json_filename = "nerfstudio/nerfstudio/viewer/app/package.json"
# version = load_from_json(Path(json_filename))["version"]
url = f"https://viewer.nerf.studio/?websocket_url={websocket_url}"
print(url)
print("You may need to click Refresh Page after you start training!")
from IPython import display
display.IFrame(src=url, height=800, width="100%")

"""# Train the model

You should keep checking the interactive viewer while the model is being trained, to see how the quality of the generated views improves with time.
"""

!pip install "numpy<2"

# Commented out IPython magic to ensure Python compatibility.
# %cd /content
import os
import time

model = 'nerfacto'  # ('nerfacto', 'instant-ngp', 'vanilla-nerf')
scene = 'custom'  # Set to "poster" for pre-processed dataset

if os.path.exists(f"data/nerfstudio/custom_data/transforms.json") and scene == 'custom':
    print(f"Training model: {model}")
    start_time = time.time()
    !ns-train {model} --viewer.websocket-port 7007 --viewer.make-share-url True nerfstudio-data --data data/nerfstudio/custom_data --downscale-factor 4
    training_time = time.time() - start_time
    print(f"Training time: {training_time:.2f} seconds")

elif os.path.exists(f"data/nerfstudio/{scene}/transforms.json") and scene == 'poster':
    print(f"Training model: {model} on pre-processed dataset")
    start_time = time.time()
    !ns-train {model} --viewer.websocket-port 7007 --viewer.make-share-url True nerfstudio-data --data data/nerfstudio/$scene --downscale-factor 4
    training_time = time.time() - start_time
    print(f"Training time: {training_time:.2f} seconds")
else:
    print('Preprocessing not complete')

!ns-eval --load-config outputs/unnamed/instant-ngp/2024-12-16_013904/config.yml

# Commented out IPython magic to ensure Python compatibility.
# @title # Render Video { vertical-output: true }
# @markdown <h3>Export the camera path from within the viewer, then run this cell.</h3>
# @markdown <h5>The rendered video should be at renders/output.mp4!</h5>


base_dir = "/content/outputs/unnamed/nerfacto/"
training_run_dir = base_dir + os.listdir(base_dir)[0]

from IPython.core.display import HTML, display

# display(HTML("<h3>Upload the camera path JSON.</h3>"))
# %cd $training_run_dir
# uploaded = files.upload()
# uploaded_camera_path_filename = list(uploaded.keys())[0]

# config_filename = training_run_dir + "/config.yml"
# camera_path_filename = training_run_dir + "/" + uploaded_camera_path_filename
# camera_path_filename = camera_path_filename.replace(" ", "\\ ").replace("(", "\\(").replace(")", "\\)")

# %cd /content/
!ns-render camera-path --load-config outputs/unnamed/nerfacto/2024-12-16_204341/config.yml --camera-path-filename /content/outputs/unnamed/nerfacto/2024-12-16_204341/camera_paths/2024-12-16-20-43-54.json --output-path renders/2024-12-16_204341/2024-12-16-20-43-54.mp4
# !ns-render camera-path --load-config $config_filename --camera-path-filename $camera_path_filename --output-path renders/output.mp4

ns-render camera-path --load-config outputs/unnamed/nerfacto/2024-12-16_204341/config.yml --camera-path-filename /content/outputs/unnamed/nerfacto/2024-12-16_204341/camera_paths/2024-12-16-20-43-54.json --output-path renders/2024-12-16_204341/2024-12-16-20-43-54.mp4